{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac84564a",
   "metadata": {},
   "source": [
    "### LLM 장착한 langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d3b0549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI # llm 모델 사용하기 위한 모듈\n",
    "from langchain_core.messages import HumanMessage, AIMessage # message 양식 처리를 위한 모듈\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6c1e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. state 정의, 모델 정의\n",
    "# 2. 노드 만들기\n",
    "# 3. 그래프 생성\n",
    "# 4. 실행해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7460d373",
   "metadata": {},
   "source": [
    "### 1. State 정의, 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6363ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatState(TypedDict):\n",
    "    user_input : str    # 처음 입력한 질문\n",
    "    llm_response : str  # AI 최종 답변\n",
    "    conversation_history : list # 그 동안의 대화 내용 저장하기\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2090f697",
   "metadata": {},
   "source": [
    "### 2. 노드 만들기\n",
    "1. 사람이 질문 일렵\n",
    "2. llm이 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "219b0bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_input(state : ChatState) -> ChatState: # 확인용\n",
    "    user_message = state.get(\"user_input\", \"\")\n",
    "    print(\"처음 입력한 메시지\", user_message)\n",
    "    print(\"=\"*50)\n",
    "    return state\n",
    "\n",
    "def call_llm(state : ChatState) -> ChatState :\n",
    "    user_message = state.get(\"user_input\", \"\")\n",
    "\n",
    "    # llm 호출\n",
    "    response = llm.invoke([HumanMessage(content=user_message)])\n",
    "    print(\"response\" ,  response)\n",
    "    print(\"-\"*50)\n",
    "    print(\"히스토리\", state.get(\"conversation_history\", []))\n",
    "    \n",
    "    print(\"response 내용\", state.get(\"response\", \"\"))   # 아직 state에 response 값을 업데이트 하지 않은 상태\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    return {\n",
    "        \"user_input\" : user_message,\n",
    "        \"llm_response\" : response,\n",
    "        \"conversation-history\" : state.get(\"conversation_history\", [])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38d06f9",
   "metadata": {},
   "source": [
    "### 그래프 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e8ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(ChatState)\n",
    "\n",
    "workflow.add_node(\"input\", get_user_input)\n",
    "workflow.add_node(\"llm\", call_llm)\n",
    "\n",
    "workflow.add_edge(\"input\", \"llm\")\n",
    "workflow.set_entry_point(\"input\")\n",
    "workflow.set_finish_point(\"llm\")\n",
    "app = workflow.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7ab495",
   "metadata": {},
   "source": [
    "### 과제\n",
    "1. llm_response 업데이트 되었는지 확인하는 노드 추가\n",
    "2. history 내용을 업데이트 하도록 노드 추가\n",
    "3. history 내용 확인하는 노드도 추가해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501f6535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 히스토리 내용이 업데이트(힌트이자 정답일지도)\n",
    "def history_add(state: ChatState) -> ChatState:\n",
    "    history = state.get(\"conversation_history\", [])\n",
    "    history.append({    # 일단 append 로 넣어보자, 나중엔 add_message 로 처리\n",
    "        \"user\": state[\"user_input\"],\n",
    "        \"ai\": state[\"llm_response\"]\n",
    "    })\n",
    "    return {\n",
    "        \"user_input\" : state[\"user_input\"],\n",
    "        \"llm_response\" : state[\"llm_response\"],\n",
    "        \"conversation_history\" : history\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "10_LangChain-Study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
